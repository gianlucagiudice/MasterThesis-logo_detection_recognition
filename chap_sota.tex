\chapter{State of the art}
\label{chap:sota}

\section{Object detection}
Object detection is one of the most fundamental and challenging problems in computer vision \cite{zou2019object}. This task can be define as follows: given an image, determine whether or not there are instances of a predefined set of objects, usually referred as classes, and, if present, return the location of each instance \cite{liu2020deep}. The spatial location of an object in an image can be represented using bounding boxes.

Object detection has initially been addressed using handcrafted features and shallow trainable architectures.
With the rapid development in deep learning, more powerful techniques are used to address the problems existing in traditional architectures \cite{zhao2019object}. 

As described in \cite{zhao2019object}, the frameworks of object detection methods can mainly be categorized into two types:
\begin{enumerate}
    \item Generating region proposals at first and then classifying each proposal into different object categories.
    \item Adopting a unified framework to achieve final results (categories and locations) directly.
\end{enumerate} 

\subsection{YOLO}
YOLO \cite{redmon2016you} is a model for object detection composed of a single neural network which treats object detection as a regression problem: given an image as input it produces bounding box coordinates and associated class probabilities. Since the predictions are performed directly on the input image without requiring complex pipelines, YOLO (you only look once) is very efficient and can lead to real-time object detection.

\begin{figure}
    \begin{center}
        \includegraphics[width=\columnwidth]{images/yolo-model.png}
    \end{center}
    \caption{Pipeline of YOLO presented in \cite{redmon2016you}.}
    \label{fig:yolo-model}
\end{figure}

In YOLO, the input image is divided into a $S \times S$ grid and the cell in which the center of the object falls is responsible for the detection of that object.
A grid cell can predict more than one bounding box, where each prediction consists of an array composed by 5 elements: center of the bounding identified by the coordinates $x$ and $y$, dimensions of the box $w$ and $h$, and the confidence score of that bounding box representing and object. At the same time, regardless of the number of boxes in each cell, C conditional probabilities $\Pr(Class_i | Object)$ are computed in each grid cell. The final prediction will be encoded as an $S \times S \times (B * 5 + C)$ tensor. The model pipeline is shown in \autoref{fig:yolo-model}


\vspace{1.5\baselineskip}
::: TODO ::: Spiegare la loss di YOLO!


Over the years, several versions of YOLO have came up, starting from the first up to fifth versions \cite{redmon2016you, redmon2017yolo9000, redmon2018yolov3, bochkovskiy2020yolov4, glenn_jocher_2021_5563715}. YOLOv5 represents the state of the art for object detection, and compared with the most recent detectors architectures it is among the best performing models \cite{zaidi2022survey}.

\section{Logo recognition}
\label{sec:sota-logoyolo}

A general pipeline for logo detection and recognition consists in logo region proposal followed by a classifier specifically trained for logo classification, as proposed by Bianco et al. in \cite{bianco2017deep} or by Fehérvári et al. in \cite{fehervari2019scalable}.

Another approach presented by Wang et al. \cite{wang2022logodet} involve a model based on YOLOv3 \cite{redmon2018yolov3} used to produce both bounding boxes and classification for each detected logo. The proposed model is called Logo-YOLO, which is essentially the same version of YOLOv3 with some changes to the loss function and the re-computation of the anchors sizes. The modified loss function utilizes the Focal Loss \cite{lin2017focal} to solve the problem of logos usually begin small object relative to the background, and the  CIoU loss \cite{zheng2020distance} to obtain more accurate regression results.

The issue with this approaches is the closed-world assumption which does not apply in the case of logo recognition, as discussed in \autoref{sec:logodet-intro}. This is the motivation behind works such as \cite{fehervari2019scalable}. The authors of the paper propose a method based on Distance Metric learning (DML) using deep learning techniques called SoftTriple Loss and presented in \cite{qian2019softtriple}. This work aims to achieve logo recognition via metric learning, where a model learns the similarity among arbitrary groups of data, thus being able to deal with a large number of previously unseen classes.

Another work based on DML has been presented by Li et al. \cite{li2022seetek} and can be considered as an extension to \cite{fehervari2019scalable}. In this work the author enrich the latent space learned by DML with text features contained in the logos. The authors point out how many logos have remarkable amount of text or (stylized) letters, for this reason they consider both visual and text features for logo classification.

\section{Class incremental learning}
Traditional supervised learning systems are trained in closed-world for a fixed
number of classes, that requires all the training data to be available before training.
The problem of class incremental learning (CIL) aims to design algorithms that can learn new concepts in a sequential way and eventually perform well on all observed classes \cite{yan2021dynamically}.

To extend a trained model on new classes, a large amount of labeled data for both new
and old classes is necessary for network finetuning. Otherwise, if the dataset of old classes is no
longer available, directly finetuning a deployed model with
new classes can lead to the catastrophic forgetting
problem \cite{serra2018overcoming, zhang2021few, mccloskey1989catastrophic}. Catastrophic forgetting means that a neural network degrades performance on old classes when retrained on new ones.

\subsection{Problem formulation}


\subsection{Methods}



\begin{figure}
    \begin{center}
        \begin{forest} for tree={align=center, inner sep=0pt}
        [Class Incremental Learning (CIL)\\methods
        [Replay\\methods
            [Rehearsal
            [
                iCaRL \cite{rebuffi2017icarl}\\
                ER \cite{rolnick2019experience}\\
                SER \cite{isele2018selective}\\
                TEM \cite{chaudhry2019continual}\\
                CoPE \cite{de2021continual}
            ]
            ]
            [Pseudo\\Rehearsal
            [
                DGR \cite{shin2017continual}\\
                PR \cite{atkinson1802pseudo}\\
                CCLUGM \cite{lavda2018continual}\\
                LGM \cite{ramapuram2020lifelong}\\
            ]
            ] 
            [Constrained
            [
                GEM \cite{lopez2017gradient}\\
                A-GEM \cite{chaudhry2018efficient}\\
                GSS \cite{aljundi2019online}\\
            ]
            ] 
        ]
        [Regularization-based\\methods
        [Prior-focused 
            [
                EWC \cite{kirkpatrick2017overcoming}\\
                IMM \cite{lee2017overcoming}\\
                SI \cite{zenke2017continual}\\
                R-EWC \cite{liu2018rotate}\\
                MAS \cite{aljundi2018memory}\\
                Riemannian Walk \cite{chaudhry2018riemannian}\\
            ]
        ]
        [Data-focused 
            [
            LwF \cite{li2017learning}\\
            LFL \cite{jung2016less}\\
            EBLL \cite{rannen2017encoder}\\
            DMC \cite{zhang2020class}\\
            ]
        ]
        ]
        [Parameter\\isolation methods
        [Fixed\\Network
            [
                PackNet \cite{mallya2018packnet}\\
                PathNet \cite{fernando2017pathnet}\\
                Piggybak \cite{mallya2018piggyback}\\
                HAT \cite{serra2018overcoming}\\
            ]
        ]
        [Dynamic\\Network
            [
                PNN \cite{rusu2016progressive}\\
                Expert Gate \cite{aljundi2017expert}\\
                RCL \cite{xu2018reinforced}\\
                DAN \cite{rosenfeld2018incremental}\\
            ]    
        ]]
        ]
        \end{forest}
    \end{center}

    \caption{CIL algorithms taxonomy presented in \cite{delange2021continual}.}
    \label{fig:yolo-model}

\end{figure}


     

The problem of CIL has been addressed using different methods, but these methods can be divided into three main categories and their sub-categories. The taxonomy and the list of algorithms is based on these publications \cite{liu2021adaptive, delange2021continual}:

 

\begin{enumerate}
    \item \textbf{Replay methods}: These works stores samples of old classes which are replayed while learning a new task, by doing so it is possible to alleviate forgetting.
    The samples are either reused as model inputs for rehearsal, or to constrain optimization of the new task loss to prevent previous task interference.

    \begin{enumerate}
        \item \textit{Rehearsal} \cite{rebuffi2017icarl, rolnick2019experience, isele2018selective, chaudhry2019continual, de2021continual}: The model is retrained on a limited subset of stored samples.
        \item \textit{Pseudo Rehearsal} \cite{shin2017continual, atkinson1802pseudo, lavda2018continual, ramapuram2020lifelong}: Approximate previous tasks samples using either random input vector or more advanced techniques like generative models with the drawback of adding complexity to the system pipeline.
        \item \textit{Constrained optimization} \cite{lopez2017gradient, chaudhry2018efficient, aljundi2019online}: Update model's weights for the new task in such a way to not interfere with previous task weights.
    \end{enumerate}
    
    \item \textbf{Regularization-based methods}: These works do not store raw data and reduce the memory requirements. An extra regularization term is introduced in the loss function, in this way it is possible to learn new classes while maintaining the previous knowledge.
    \begin{enumerate}
        \item \textit{Prior-focused methods} \cite{kirkpatrick2017overcoming, lee2017overcoming, zenke2017continual, liu2018rotate, aljundi2018memory, chaudhry2018riemannian}: This approach tries to estimate the importance of the neural network parameters to avoid forgetting as much as possible. Then, when training on new tasks, the optimization process penalizes changes to important weights.
        \item \textit{Data-focused methods} \cite{li2017learning, jung2016less, zhang2020class, rannen2017encoder}: This approach uses knowledge distillation \cite{hinton2015distilling} treating the old model trained on the previous task as the teacher, and use it combined with the new data to train the student model.
    \end{enumerate}
    \item \textbf{Parameter isolation methods}: This class of methods use different model parameters for each task.
    \begin{enumerate}
        \item \textit{Fixed Network} \cite{mallya2018packnet, mallya2018piggyback, serra2018overcoming, fernando2017pathnet}: The model architecture is kept fixed and the knowledge is updated involving masks for the parameters' weights.
        \item \textit{Dynamic Architectures} \cite{rusu2016progressive, xu2018reinforced, aljundi2017expert, rosenfeld2018incremental}: The model architecture dynamically change after each incremental task, and the old parameters are freezed to prevent forgetting. Another approach is to dedicate a model to each incremental task
    \end{enumerate}
\end{enumerate}

\subsection{DER: an algorithm for class incremental learning}
\subsubsection{Algorithm description}
\subsubsection{Weight aligning}
\subsubsection{Masking and pruning}
